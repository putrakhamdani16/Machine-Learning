{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG-jpdfvxvNP"
   },
   "source": [
    "# Praktikum 2 - Klasifikasi Berita dengan Perceptron\n",
    "\n",
    "**Nama : Nanda Putra Khamdani**\n",
    "\n",
    "**Kelas : TI-3H / 18**\n",
    "\n",
    "**NIM : 2241720180**\n",
    "\n",
    "### Deskripsi\n",
    "\n",
    "Dalam kasus ini, Anda akan melakukan klasifiaksi berita berdasarkan 3 kategori, yaitu Sport Hockey, Sport Baseball, dan Otomotif. Proses klasifikasi akan menggunakan model Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kPX0T_Bx1bb"
   },
   "source": [
    "* Langkah 1 - Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5ZwV7xB1xtJv"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups # download dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0RAGhGrx9dG"
   },
   "source": [
    "* Langkah 2 - Pilih Label dan Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3zsu9HmWx_Zh"
   },
   "outputs": [],
   "source": [
    "categories = ['rec.sport.hockey', 'rec.sport.baseball', 'rec.autos']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas memuat dataset 20 Newsgroups, yang berisi kumpulan artikel dari berbagai kategori, dengan memilih tiga kategori khusus, yaitu rec.sport.hockey, rec.sport.baseball, dan rec.autos. Dataset ini dipecah menjadi dua bagian: newsgroups_train yang digunakan sebagai data latih, dan newsgroups_test sebagai data uji, masing-masing diambil dari subset yang relevan. Selain itu, bagian header, footer, dan kutipan dari artikel dihapus menggunakan parameter remove=('headers', 'footers', 'quotes') agar model dapat fokus hanya pada isi teks utama dari artikel untuk analisis atau pelatihan lebih lanjut.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reWcWmYiyCRI"
   },
   "source": [
    "* Langkah 3 - Ekstrak Fitur dan Buat Model Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5RjlnwvyDY3",
    "outputId": "36a53e54-b8d1-4f0b-c260-0fbe881f72e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       396\n",
      "           1       0.82      0.83      0.83       397\n",
      "           2       0.88      0.87      0.87       399\n",
      "\n",
      "    accuracy                           0.86      1192\n",
      "   macro avg       0.86      0.86      0.86      1192\n",
      "weighted avg       0.86      0.86      0.86      1192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ekstrak Fitur\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit fitur\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Fit Model\n",
    "clf = Perceptron(random_state=11)\n",
    "clf.fit(X_train, newsgroups_train.target)\n",
    "\n",
    "# Prediksi\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(newsgroups_test.target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas melakukan proses ekstraksi fitur, pelatihan model, dan evaluasi prediksi menggunakan dataset 20 Newsgroups. Pertama, fitur teks dari artikel diubah menjadi representasi numerik menggunakan TF-IDF melalui objek TfidfVectorizer. Data latih X_train dibentuk dengan memanggil fit_transform pada teks dari newsgroups_train, dan data uji X_test diubah menggunakan metode transform dari teks newsgroups_test.\n",
    "\n",
    "Selanjutnya, model Perceptron dilatih menggunakan data latih X_train dan target label dari newsgroups_train. Setelah model dilatih, prediksi dilakukan pada data uji X_test, dan hasil prediksi dibandingkan dengan label sebenarnya dari newsgroups_test. Terakhir, laporan klasifikasi dicetak menggunakan classification_report, yang menampilkan metrik evaluasi seperti presisi, recall, dan F1-score.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU_G6yJByOuS"
   },
   "source": [
    "**Penjelasan**\n",
    "\n",
    "Dataset yang digunakan pada kode program diatas adalah 20newsgroup yang terdiri dari sekitar 20.000 dokumen. Scikit-learn bahkan menyediakan fungsi yang memberikan kemudahan untuk mengunduh dan membaca kumpulan dataset dengan menggunakan sklearn.datasets. pada kode program diatas Perceptron mampu melakukan klasifikasi multikelas; strategi yang digunakan adalah one-versus-all untuk melakukan pelatihan untuk setiap kelas dalam data training. Dokumen teks memerlukan ekstraksi fitur salah satunya adalah bobot tf-idf pada kodeprogram diatas digunakan tfidf-vectorizer.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMA+pWf5nokCq7+aCcjFQzi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
